{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMn3ZwTxJFwj8hPOYcVJ13o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1kaiser/parvati_track_analysis/blob/main/ICESAT_2_Tracks_plot_parvati_basin.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xY0iElejsUv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# prerequisite   [**Work Book**](docs.google.com/spreadsheets/d/1bYvEQ2ckp-xSrT_Xsa-lAnW3MEQU9K8AnXNjGL81C4g) **for processing links from earth data cloud ALT03 tracks in the region of ICESAT 2**\n"
      ],
      "metadata": {
        "id": "zXzj--gKOogA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [**Work Book**](docs.google.com/spreadsheets/d/1bYvEQ2ckp-xSrT_Xsa-lAnW3MEQU9K8AnXNjGL81C4g) **for processing links from earth data cloud ALT03 tracks in the region of ICESAT 2**"
      ],
      "metadata": {
        "id": "UftojGa1oItJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q20xiCSi-OTU"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "list_B = [\n",
        "    \n",
        "    \"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/222973190/processed_ATL03_20181027214446_04470106_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/223195374/processed_ATL03_20181106091229_05920102_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/223250510/processed_ATL03_20181125202044_08890106_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/223436762/processed_ATL03_20181224185651_13310106_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/223460364/processed_ATL03_20190107061605_01500202_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/223502286/processed_ATL03_20190126172441_04470206_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/223749350/processed_ATL03_20190205045217_05920202_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/223776492/processed_ATL03_20190224160046_08890206_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/224716605/processed_ATL03_20190310031957_10950202_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/224749590/processed_ATL03_20190325143645_13310206_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/224762983/processed_ATL03_20190408015557_01500302_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/224813989/processed_ATL03_20190427130425_04470306_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/224842242/processed_ATL03_20190507003154_05920302_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/224925276/processed_ATL03_20200606053844_10950702_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/224931112/processed_ATL03_20190526114022_08890306_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/224987981/processed_ATL03_20200621165535_13310706_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/225035619/processed_ATL03_20190727084402_04470406_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/225052292/processed_ATL03_20190825072010_08890406_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/225056324/processed_ATL03_20190805201136_05920402_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/225084620/processed_ATL03_20190907183921_10950402_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/225102664/processed_ATL03_20190923055616_13310406_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/225148457/processed_ATL03_20191026042400_04470506_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/225149213/processed_ATL03_20191006171527_01500502_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/225173925/processed_ATL03_20191124030002_08890506_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/225192917/processed_ATL03_20191104155130_05920502_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/225264551/processed_ATL03_20191207141910_10950502_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/225300326/processed_ATL03_20191223013603_13310506_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/225446577/processed_ATL03_20200125000345_04470606_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/225470138/processed_ATL03_20200105125512_01500602_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/225512963/processed_ATL03_20200203113114_05920602_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/225526832/processed_ATL03_20200222223946_08890606_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/225537969/processed_ATL03_20200307095855_10950602_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/225568889/processed_ATL03_20200322211548_13310606_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/225698437/processed_ATL03_20200405083458_01500702_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/225784710/processed_ATL03_20200424194334_04470706_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/225786779/processed_ATL03_20200504071102_05920702_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/225805997/processed_ATL03_20200523181936_08890706_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/225826127/processed_ATL03_20200705041445_01500802_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/225877567/processed_ATL03_20200724152319_04470806_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/225883138/processed_ATL03_20200803025049_05920802_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/225883642/processed_ATL03_20200822135921_08890806_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/225932278/processed_ATL03_20200905011831_10950802_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/225934426/processed_ATL03_20200920123523_13310806_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/225969281/processed_ATL03_20201003235429_01500902_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/225991504/processed_ATL03_20201023110305_04470906_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/226007969/processed_ATL03_20201101223037_05920902_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/226030279/processed_ATL03_20190624101622_13310306_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/226034518/processed_ATL03_20201121093911_08890906_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/226037168/processed_ATL03_20190608225932_10950302_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/226151035/processed_ATL03_20201204205822_10950902_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/226209521/processed_ATL03_20201220081515_13310906_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/226323418/processed_ATL03_20210122064302_04471006_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/226431943/processed_ATL03_20210131181032_05921002_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/226435887/processed_ATL03_20210102193427_01501002_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/226488249/processed_ATL03_20210220051904_08891006_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/226545834/processed_ATL03_20210305163815_10951002_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/226578361/processed_ATL03_20210403151419_01501102_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/226628652/processed_ATL03_20210321035506_13311006_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/226709985/processed_ATL03_20210502135022_05921102_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/226731807/processed_ATL03_20210423022251_04471106_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/226836774/processed_ATL03_20210522005855_08891106_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/226844002/processed_ATL03_20210604121806_10951102_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/226873213/processed_ATL03_20210619233457_13311106_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/226944646/processed_ATL03_20210703105408_01501202_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/232756362/processed_ATL03_20210722220243_04471206_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/232840255/processed_ATL03_20210903075800_10951202_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/232917135/processed_ATL03_20210820203849_08891206_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/233093014/processed_ATL03_20210801093014_05921202_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/233105251/processed_ATL03_20210918191454_13311206_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/239087184/processed_ATL03_20211002063408_01501302_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/239095024/processed_ATL03_20211031051013_05921302_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/239105858/processed_ATL03_20211021174241_04471306_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/239628887/processed_ATL03_20211119161851_08891306_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/239629274/processed_ATL03_20211218145451_13311306_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/242067092/processed_ATL03_20220120132233_04471406_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/242098095/processed_ATL03_20220101021400_01501402_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/242098349/processed_ATL03_20220130005003_05921402_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/242780024/processed_ATL03_20220303231746_10951402_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/242797282/processed_ATL03_20220401215352_01501502_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/242802167/processed_ATL03_20220218115836_08891406_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/242828459/processed_ATL03_20220319103442_13311406_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/244257256/processed_ATL03_20220430202954_05921502_005_02.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/244286824/processed_ATL03_20220520073827_08891506_005_02.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/244303300/processed_ATL03_20220421090223_04471506_005_02.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/244335476/processed_ATL03_20220602185744_10951502_005_02.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/247840898/processed_ATL03_20220701173348_01501602_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/247994909/processed_ATL03_20220618061433_13311506_005_02.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/248052344/processed_ATL03_20220730160956_05921602_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/248080548/processed_ATL03_20220721044220_04471606_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/256168401/processed_ATL03_20220819031826_08891606_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/256229760/processed_ATL03_20220901143739_10951602_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/256231766/processed_ATL03_20220930131341_01501702_005_01.h5\",\n",
        "\"https://n5eil02u.ecs.nsidc.org/esir/5000004201583/256292765/processed_ATL03_20220917015428_13311606_005_01.h5\",\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "for i in list_B:\n",
        "  !wget --http-user=kroy0001 --http-password=/#j%kWrPA,8.HRe {i}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHoaOoaEy_qN"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/1kaiser/ICESAT2/releases/download/1/ASTER_DEM.tif #getting the dem\n",
        "!wget https://github.com/1kaiser/ICESAT2/releases/download/1/pongdam_dem.tif #getting Pong Dam dem\n",
        "!wget https://github.com/1kaiser/ICESAT2/releases/download/1/landsat2.zip\n",
        "!unzip '*.zip'\n",
        "!rm -r *.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install geopandas\n",
        "!pip install rasterio"
      ],
      "metadata": {
        "id": "zA5D3GXo9lew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# preparation for **plotting in river buffer**"
      ],
      "metadata": {
        "id": "d3MqLvFb9Ztk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#downloading river buffer\n",
        "!wget https://github.com/1kaiser/ICESAT2/releases/download/1/parvati_catchment.zip\n",
        "!unzip parvati_catchment.zip -d parvati_catchment\n",
        "#downloading catchment\n",
        "!wget https://github.com/1kaiser/ICESAT2/releases/download/1/parvati_river_buffer.zip\n",
        "!unzip parvati_river_buffer.zip -d parvati_river_buffer\n",
        "#parallel downloading of ICESAT 2 tracks\n",
        "!wget https://github.com/1kaiser/ICESAT2/releases/download/1/parvati_tracks.txt\n",
        "import multiprocessing as mp\n",
        "import subprocess\n",
        "import re\n",
        "# Define the regex pattern to match the links\n",
        "pattern = r\"https://n5eil02u.ecs.nsidc.org/esir/.*?\\.h5\"\n",
        "with open(\"parvati_tracks.txt\", \"r\") as file:\n",
        "    contents = file.read()\n",
        "list_C = re.findall(pattern, contents)\n",
        "\n",
        "# Define the function to download a file using wget\n",
        "def download_file(url):\n",
        "    subprocess.Popen(['wget', '--http-user=kroy0001', '--http-password=/#j%kWrPA,8.HRe', url]).wait()\n",
        "\n",
        "# Create a pool of processes to download the files\n",
        "num_processes = mp.cpu_count() * 2\n",
        "pool = mp.Pool(processes=num_processes)\n",
        "results = [pool.apply_async(download_file, args=(url,)) for url in list_C]\n",
        "\n",
        "# Wait for all the processes to finish\n",
        "for r in results:\n",
        "    r.wait()"
      ],
      "metadata": {
        "id": "1I-V9d0KyvEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**funny day**"
      ],
      "metadata": {
        "id": "A_MvTe54P6mW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install geopandas"
      ],
      "metadata": {
        "id": "G9BaGKAXP-gM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title filing { vertical-output: true }\n",
        "import h5py\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import re\n",
        "import datetime\n",
        "from shapely.geometry import Point\n",
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "# Load the vector file\n",
        "vector_file = \"/content/parvati_river_buffer/Export_Output.shp\"\n",
        "region = gpd.read_file(vector_file)\n",
        "\n",
        "def get_height_lat_lon(filename, track_name):\n",
        "  # Open the HDF5 file and extract data\n",
        "  f = h5py.File(filename, 'r')\n",
        "  h_ph_data = f['/'+str(track_name)+'/heights/h_ph']\n",
        "  lat_ph_data = f['/'+str(track_name)+'/heights/lat_ph']\n",
        "  lon_ph_data = f['/'+str(track_name)+'/heights/lon_ph']\n",
        "  file_name = np.array([filename] * len(h_ph_data))\n",
        "  track_name = np.array([track_name] * len(h_ph_data))\n",
        "  return np.column_stack((file_name, track_name, lon_ph_data, lat_ph_data, h_ph_data))\n",
        "\n",
        "# Define the track names to be checked\n",
        "track_names = [\"gt1l\", \"gt1r\", \"gt2l\", \"gt2r\", \"gt3l\", \"gt3r\"]\n",
        "\n",
        "h5_files = glob.glob(\"*.h5\")\n",
        "file_list = []\n",
        "\n",
        "for filename in h5_files:\n",
        "  try:\n",
        "    f = h5py.File(filename, 'r')\n",
        "    for track_name in track_names:\n",
        "      np.array(f['/'+str(track_name)+'/heights/h_ph'])\n",
        "      file_list.append((filename, track_name)) # Append (filename, track_name) tuple to file_list\n",
        "  except KeyError:\n",
        "    count = 0\n",
        "\n",
        "clipped_points_array = []\n",
        "\n",
        "h5_files = file_list\n",
        "count = 0\n",
        "def process_data_by_year(h5_files, year, region):\n",
        "    for filename, track in tqdm(h5_files):\n",
        "        date_string = re.search(r'processed_ATL03_(\\d{8})', filename).group(1)\n",
        "        date_object = datetime.datetime.strptime(date_string, \"%Y%m%d\").date().year\n",
        "        if date_object == year:\n",
        "            try:\n",
        "                track_data = get_height_lat_lon(filename, track)\n",
        "                np.save(f'point_cloud_{filename[:-3]}_{track}.npy', track_data)\n",
        "                point_cloud_file = f'point_cloud_{filename[:-3]}_{track}.npy'\n",
        "                point_cloud = np.load(point_cloud_file, allow_pickle=True)\n",
        "                file_names, track_names, lon, lat, h_ph_data = point_cloud[:, 0], point_cloud[:, 1], point_cloud[:, 2], point_cloud[:, 3], point_cloud[:, 4]\n",
        "                geometry = [Point(lon[i], lat[i]) for i in range(len(lon))]\n",
        "                data = gpd.GeoDataFrame({'file_name': file_names, 'track_name': track_names,'h_ph_data': h_ph_data, 'lat': lat, 'lon': lon},geometry=geometry, crs=region.crs)\n",
        "                clipped_points = gpd.sjoin(data, region, op='within')\n",
        "                clipped_points_array.append(np.column_stack((clipped_points['file_name'], clipped_points['track_name'], clipped_points['h_ph_data'], clipped_points['lat'], clipped_points['lon'])))\n",
        "\n",
        "                # fig, ax = plt.subplots(figsize=(10, 6))\n",
        "                # region.plot(ax=ax, color='white', edgecolor='black')\n",
        "                # data.plot(ax=ax, column='h_ph_data', markersize=1)\n",
        "\n",
        "                # plt.title(\"Points inside the Buffered Vector\")\n",
        "                # plt.legend()\n",
        "                # plt.show()\n",
        "            except KeyError:\n",
        "                count += 1\n",
        "# year_list = [2018, 2019, 2020, 2021, 2022]\n",
        "year_list = [2021]\n",
        "\n",
        "for x in year_list:\n",
        "  process_data_by_year(h5_files, x, region)\n",
        "\n",
        "np.save('clipped_points.npy', clipped_points_array)\n"
      ],
      "metadata": {
        "id": "f-Yg431cP-gM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "190d321b-142f-4470-d534-d16cc5016272"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/124 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **plotting functions**\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import medfilt\n",
        "\n",
        "# Define haversine function\n",
        "def haversine(lat1, lon1, lat2, lon2):\n",
        "    R = 6371.0  # Earth radius in km\n",
        "    dLat, dLon = np.radians(lat2 - lat1), np.radians(lon2 - lon1)\n",
        "    lat1, lat2 = np.radians(lat1), np.radians(lat2)\n",
        "    a = np.sin(dLat/2)**2 + np.cos(lat1)*np.cos(lat2)*np.sin(dLon/2)**2\n",
        "    c = 2*np.arcsin(np.sqrt(a))\n",
        "    return R*c*1000.0\n",
        "\n",
        "def elevation_plot(data, window_size=17, k=3):\n",
        "    # Load data from .npy file\n",
        "    # data = np.load(np_file, allow_pickle=True)\n",
        "\n",
        "    # Extract latitude, longitude, and elevation data\n",
        "    lon, lat, elev = data[:,4].astype(float), data[:,3].astype(float), data[:,2].astype(float)\n",
        "    # Calculate linear distance between points\n",
        "    dist = np.zeros_like(lat)\n",
        "    for i in range(1, len(lat)):\n",
        "        dist[i] = dist[i-1] + haversine(lat[i-1], lon[i-1], lat[i], lon[i])\n",
        "\n",
        "    # Apply Hampel filter with specified window size and threshold\n",
        "    filtered_data = hampel_filter(elev, window_size, k)\n",
        "\n",
        "    # Apply median filter with window size of 17 to filtered data\n",
        "    median_filtered_data = medfilt(filtered_data, kernel_size=17)\n",
        "\n",
        "    # Add a smooth moving average over the median filtered data.\n",
        "    smooth_moving_average = np.convolve(median_filtered_data, np.ones(5)/5, mode='same')\n",
        "\n",
        "    # for i in range(0,10):\n",
        "    #   filtered_data = hampel_filter(smooth_moving_average, window_size, k)\n",
        "    #   median_filtered_data = medfilt(filtered_data, kernel_size=17)\n",
        "    #   smooth_moving_average = np.convolve(median_filtered_data, np.ones(5)/5, mode='same')\n",
        "\n",
        "    # Create scatter plot\n",
        "    fig, ax = plt.subplots(figsize=(10, 5), dpi=300)\n",
        "    ax.scatter(dist, elev, label=\"Original data\", s=1)\n",
        "    ax.scatter(dist, filtered_data, label=\"Hampel filtered data\", s=1)\n",
        "    ax.scatter(dist, median_filtered_data, label=\"Median filtered data\", s=1)\n",
        "    ax.scatter(dist, smooth_moving_average, label=\"Smooth moving average\", s=1, c='r')\n",
        "    ax.set_aspect('equal')\n",
        "    ax.set_xlabel('Linear Distance (m)')\n",
        "    ax.set_ylabel('Elevation (m)')\n",
        "    ax.set_title('Elevation Profile '+data[0,0]+' '+data[0,1])\n",
        "    ax.legend()\n",
        "\n",
        "    # Calculate the y limits based on the median of smooth moving average +- 100m\n",
        "    median_smooth_avg = np.median(smooth_moving_average)\n",
        "    y_min = median_smooth_avg - 100\n",
        "    y_max = median_smooth_avg + 100\n",
        "    ax.set_ylim(y_min, y_max)\n",
        "\n",
        "    # Calculate the x limits based on the median of the y-axis limits ±200m\n",
        "    x_min = np.median(ax.get_xlim()) - 100\n",
        "    x_max = np.median(ax.get_xlim()) + 100\n",
        "    ax.set_xlim(x_min, x_max)\n",
        "\n",
        "    # Find the index of the x-center\n",
        "    x_center = np.median(ax.get_xlim())\n",
        "    x_center_index = np.abs(dist - x_center).argmin()\n",
        "\n",
        "    # Get the y-value of the smooth moving average at the x-center\n",
        "    y_center = smooth_moving_average[x_center_index]\n",
        "\n",
        "    # Add annotation for the center point of x-axis limits\n",
        "    ax.annotate(f'Center ({x_center}, {y_center:.2f})', xy=(x_center, y_center), xytext=(x_center, y_center - 50),\n",
        "                arrowprops=dict(facecolor='black', arrowstyle='->'), ha='center')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Hampel filter\n",
        "def hampel_filter(data, window_size, k):\n",
        "    filtered_data = data.copy()\n",
        "    for i in range(len(data) - window_size + 1):\n",
        "        median = np.median(data[i:i + window_size])\n",
        "        mad = np.median(np.abs(data[i:i + window_size] - median))\n",
        "        threshold = k * mad\n",
        "        for j in range(window_size):\n",
        "            if np.abs(data[i + j] - median) > threshold:\n",
        "                filtered_data[i + j] = median\n",
        "\n",
        "    return filtered_data\n"
      ],
      "metadata": {
        "id": "nmlUt0teDQJU",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "point_cloud_file = f'/content/clipped_points.npy'\n",
        "P_C = np.load(point_cloud_file, allow_pickle=True)\n",
        "PC_list =[]\n",
        "for point_cloud in P_C:\n",
        "  if len(point_cloud) != 0:\n",
        "    PC_list.append(point_cloud)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,5))\n",
        "region.plot(ax=ax, color='white', edgecolor='black')\n",
        "\n",
        "for point_cloud in PC_list:\n",
        "  # Extract the file names, track names, and point cloud data from the numpy array\n",
        "  file_names = point_cloud[:, 0]\n",
        "  track_names = point_cloud[:, 1]  \n",
        "  h_ph_data = point_cloud[:, 2]\n",
        "  lat = point_cloud[:, 3]\n",
        "  lon = point_cloud[:, 4]\n",
        "\n",
        "  # Create a GeoDataFrame for the point cloud data\n",
        "  geometry = [Point(lon[i], lat[i]) for i in range(len(lon))]\n",
        "  data = gpd.GeoDataFrame({'file_name': file_names, 'track_name': track_names,'h_ph_data': h_ph_data, 'lat': lat, 'lon': lon}, geometry=geometry, crs=region.crs)\n",
        "\n",
        "  # Spatially join the points with the region to get the clipped points\n",
        "  clipped_points = gpd.sjoin(data, region, op='within')\n",
        "  clipped_points.plot(ax=ax, column='h_ph_data', markersize=1)\n",
        "\n",
        "  first_points = clipped_points.groupby('track_name').first()\n",
        "  for idx, row in first_points.iterrows():\n",
        "    point = row['geometry']\n",
        "    label = row['file_name']\n",
        "    ax.annotate(label, xy=(point.x, point.y), xytext=(3, 3), textcoords=\"offset points\", fontsize=8, color='red')\n",
        "    \n",
        "  elevation_plot(point_cloud, window_size=17, k=3)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1njBn1CGwOIP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}